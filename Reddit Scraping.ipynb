{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Script for running at night or unattended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new script is set to go to r/funny and get the first 100 posts in 'new' section and follow those 100 posts for 24hrs, collecting upvotes, # of comments, and subreddit activity every 30minutes.\n",
    "\n",
    "If automated script below fails, go to 'manual script' section and manually run that cell once every 30 minutes to keep adding to the data before the time of failure. (Since it should be saved before failure, you will manually add to that data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "reddit = praw.Reddit(client_id='eOqj6Q2BiQQyKQ', client_secret='1hqeAwOvlkY1PYw51ewhbrItd5k', user_agent='Reddit WebScrapping')\n",
    "\n",
    "sub_title = 'funny' #title of subreddit to scrape\n",
    "\n",
    "time2sleep = 1800 #how long the program should sleep before continuing\n",
    "hours = 48 #how long(30 minute intervals) you want to run the script for\n",
    "count = 0 #each count represents 1 interval passing\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "weekday = dt_object.strftime('%A')\n",
    "\n",
    "fname_votes = './{}_votes.csv'.format(weekday)\n",
    "fname_comments = './{}_comments.csv'.format(weekday)\n",
    "fname_online = './{}_online_users.csv'.format(weekday)\n",
    "\n",
    "votes = {} #store post ids and votes. Positive votes and NEGATIVE votes (when post.downs is > 0)\n",
    "totalcomments = {} #store post ids and the corresponding number of comments\n",
    "online = {'timestamp':[],'users_online':[]} #store number of online users and timestamp of subreddit\n",
    "\n",
    "subred = reddit.subreddit(sub_title)\n",
    "\n",
    "#get 100 posts from new\n",
    "sub_posts = subred.new(limit=100)\n",
    "\n",
    "#initialize the storage of the 100 posts that we are tracking\n",
    "for post in sub_posts:\n",
    "    pid = str(post.id)\n",
    "    if pid not in votes: #if new post, add it to the dictionary\n",
    "        votes[pid] = [] #initialize empty list\n",
    "        totalcomments[pid] = [] #initialize empty list\n",
    "    else:#just in case we get some repeating posts\n",
    "        pass\n",
    "\n",
    "while (count < hours):\n",
    "    \n",
    "    print('Starting 30min interval {}'.format(count))\n",
    "    \n",
    "    #every 30minutes store number of online users in the subreddit\n",
    "    online['timestamp'].append(time.time())\n",
    "    online['users_online'].append(subred.active_user_count)\n",
    "    \n",
    "    for id_val in votes.keys():\n",
    "        result = reddit.submission(id=id_val) #go to the specific post\n",
    "        votes[id_val].append(result.ups - result.downs) #get the current number of upvotes and add to the list\n",
    "        totalcomments[id_val].append(result.num_comments) #get number of comments\n",
    "        \n",
    "    #store into csv every 30min interval in case something goes wrong halfway through\n",
    "    upvotes = pd.DataFrame(list(votes.values()),index=votes.keys())\n",
    "    upvotes.to_csv(fname_votes,index_label='id')\n",
    "\n",
    "    comments = pd.DataFrame(list(totalcomments.values()),index=totalcomments.keys())\n",
    "    comments.to_csv(fname_comments,index_label='id')\n",
    "\n",
    "    on = pd.DataFrame(list(online.values()),index=online.keys())\n",
    "    on.to_csv(fname_online,index_label='timestamp')\n",
    "    \n",
    "    if count == hours - 1:\n",
    "        print('finished collecting data')\n",
    "        break\n",
    "    else:\n",
    "        print('sleeping for {} seconds...'.format(time2sleep))\n",
    "        time.sleep(time2sleep)\n",
    "        count+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "reddit = praw.Reddit(client_id='eOqj6Q2BiQQyKQ', client_secret='1hqeAwOvlkY1PYw51ewhbrItd5k', user_agent='Reddit WebScrapping')\n",
    "\n",
    "sub_title = 'funny' #title of subreddit to scrape\n",
    "\n",
    "time2sleep = 1800 #how long the program should sleep before continuing\n",
    "hours = 48 #how long(hours) you want to run the script for\n",
    "num_data = 48 #how many datapoints we want per post\n",
    "count = 0 #each count represents 1 interval passing\n",
    "\n",
    "votes = {} #store post ids and votes. Positive votes and NEGATIVE votes (when post.downs is > 0)\n",
    "totalcomments = {} #store post ids and the corresponding number of comments\n",
    "timestamps = {} #store timestamp of post creation just so we can tell what day/hour\n",
    "online = {'timestamp':[],'users_online':[]} #store number of online users and timestamp of subreddit\n",
    "\n",
    "subred = reddit.subreddit(sub_title)\n",
    "\n",
    "while (count < hours):\n",
    "    \n",
    "    print('Starting hour {}'.format(count))\n",
    "    \n",
    "    if count < int(hours/2):\n",
    "        sub = reddit.subreddit(sub_title).new(limit=20) #collect first X values in 'new' section\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    online['timestamp'].append(time.time())\n",
    "    online['users_online'].append(subred.active_user_count)\n",
    "    \n",
    "    #first loop through should produce nothing since there is nothing inside post_id\n",
    "    for id_val in votes.keys():\n",
    "        '''\n",
    "        We want to follow each post for 24hrs so at max we need 24 datapoints per post.\n",
    "        A fresh post collected at hour 23 would then need an extra 24hrs to get 24 datapoints\n",
    "        but we also do not want to collect more data from the previous posts at hour1,2, etc.\n",
    "        '''\n",
    "        if len(votes[id_val]) != num_data: #if we do not have X datapoints\n",
    "            result = reddit.submission(id=id_val) #go to the specific post\n",
    "            votes[id_val].append(result.ups - result.downs) #get the current number of upvotes and add to the list\n",
    "            totalcomments[id_val].append(result.num_comments) #get number of comments\n",
    "        else:\n",
    "            pass #do nothing if we already collected data from a post for 24hrs\n",
    "        \n",
    "    for post in sub:\n",
    "        pid = str(post.id)\n",
    "        if pid not in votes: #if new post, add it to the dictionary\n",
    "            votes[pid] = [post.ups - post.downs] #get the upvotes of the post\n",
    "            totalcomments[pid] = [post.num_comments] #get number of comments\n",
    "            timestamps[pid] = [post.created_utc] #store the timestamps of each post. still need to convert later.\n",
    "        else:#just in case we get some repeating posts\n",
    "            pass\n",
    "    if count == hours - 1:\n",
    "        print('finished collecting data')\n",
    "        break\n",
    "    else:\n",
    "        print('sleeping...')\n",
    "        time.sleep(time2sleep)\n",
    "        count+=0.5 #change count depending to +=0.5 for 30min intervals or +=1 for 1hr intervals\n",
    "    \n",
    "upvotes = pd.DataFrame(list(votes.values()),index=votes.keys())\n",
    "upvotes.to_csv('./votes.csv',index_label='id')\n",
    "\n",
    "comments = pd.DataFrame(list(totalcomments.values()),index=totalcomments.keys())\n",
    "comments.to_csv('./comments.csv',index_label='id')\n",
    "\n",
    "times = pd.DataFrame(list(timestamps.values()),index=timestamps.keys())\n",
    "times.to_csv('./post_time.csv',index_label='id')\n",
    "\n",
    "on = pd.DataFrame(list(online.values()),index=online.keys())\n",
    "on.to_csv('./online_users.csv',index_label='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell below manually every 30minutes to collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "reddit = praw.Reddit(client_id='eOqj6Q2BiQQyKQ', client_secret='1hqeAwOvlkY1PYw51ewhbrItd5k', user_agent='Reddit WebScrapping')\n",
    "\n",
    "sub_title = 'funny' #title of subreddit to scrape\n",
    "\n",
    "dt_object = datetime.fromtimestamp(time.time())\n",
    "weekday = dt_object.strftime('%A')\n",
    "\n",
    "fname_votes = './{}_votes.csv'.format(weekday)\n",
    "df_votes = pd.read_csv(fname_votes)\n",
    "#df_votes.set_index('id',inplace=True)\n",
    "\n",
    "fname_comments = './{}_comments.csv'.format(weekday)\n",
    "df_comments = pd.read_csv(fname_comments)\n",
    "#df_comments.set_index('id',inplace=True)\n",
    "\n",
    "fname_online = './{}_online_users.csv'.format(weekday)\n",
    "df_online = pd.read_csv(fname_online)\n",
    "#df_online.set_index('timestamp',inplace=True)\n",
    "\n",
    "votes = {} #store post ids and votes. Positive votes and NEGATIVE votes (when post.downs is > 0)\n",
    "totalcomments = {} #store post ids and the corresponding number of comments\n",
    "online = {'timestamp':[],'users_online':[]} #store number of online users and timestamp of subreddit\n",
    "\n",
    "subred = reddit.subreddit(sub_title)\n",
    "\n",
    "#initialize the storage of the 100 posts that we are tracking\n",
    "for pid in df_votes['id']:\n",
    "    if pid not in votes: #if new post, add it to the dictionary\n",
    "        votes[pid] = [] #initialize empty list\n",
    "        totalcomments[pid] = [] #initialize empty list\n",
    "    else:#just in case we get some repeating posts\n",
    "        pass\n",
    "\n",
    "#get online users\n",
    "online['timestamp'].append(time.time())\n",
    "online['users_online'].append(subred.active_user_count)\n",
    "    \n",
    "#get votes/comments\n",
    "for id_val in votes.keys():\n",
    "    result = reddit.submission(id=id_val) #go to the specific post\n",
    "    votes[id_val].append(result.ups - result.downs) #get the current number of upvotes and add to the list\n",
    "    totalcomments[id_val].append(result.num_comments) #get number of comments\n",
    "        \n",
    "#create into dataframe, merge with old, and save to csv\n",
    "temp = pd.DataFrame(list(votes.values()),index=votes.keys())\n",
    "#temp.index.names = ['id']\n",
    "df_votes.set_index('id',inplace=True)\n",
    "upvotes = pd.concat([df_votes,temp],axis=1)\n",
    "upvotes.to_csv(fname_votes,index_label='id')\n",
    "\n",
    "temp = pd.DataFrame(list(totalcomments.values()),index=totalcomments.keys())\n",
    "#temp.index.names = ['id']\n",
    "df_comments.set_index('id',inplace=True)\n",
    "comments = pd.concat([df_comments,temp],axis=1)\n",
    "comments.to_csv(fname_comments, index_label='id')\n",
    "\n",
    "temp = pd.DataFrame(list(online.values()),index=online.keys())\n",
    "#temp.index.names = ['timestamp']\n",
    "df_online.set_index('timestamp',inplace=True)\n",
    "on = pd.concat([df_online,temp],axis=1)\n",
    "on.to_csv(fname_online, index_label='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the first 2 cells below when you first begin in order to initialize stuff. Afterwards, run the 3rd cell (the one that only has one line) every 1hr or 30mins or however often you want to collect data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell once for initialization or if you made changes to the function\n",
    "\n",
    "import time\n",
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "def get_data(sub_title, subred, reddit, votes, totalcomments, timestamps, online, num_data):\n",
    "    \n",
    "    sub = reddit.subreddit(sub_title).new(limit=20) #collect first X values in 'new' section\n",
    "    online['timestamp'].append(time.time())\n",
    "    online['users_online'].append(subred.active_user_count)\n",
    "    \n",
    "    #first loop through should produce nothing since there is nothing inside post_id\n",
    "    for id_val in votes.keys():\n",
    "        '''\n",
    "        We want to follow each post for 24hrs so at max we need 24 datapoints per post.\n",
    "        A fresh post collected at hour 23 would then need an extra 24hrs to get 24 datapoints\n",
    "        but we also do not want to collect more data from the previous posts at hour1,2, etc.\n",
    "        '''\n",
    "        if len(votes[id_val]) != num_data: #if we do not have 24 datapoints\n",
    "            result = reddit.submission(id=id_val) #go to the specific post\n",
    "            votes[id_val].append(result.ups - result.downs) #get the current number of upvotes and add to the list\n",
    "            totalcomments[id_val].append(result.num_comments) #get number of comments\n",
    "        else:\n",
    "            pass #do nothing if we already collected data from a post for 24hrs\n",
    "        \n",
    "    for post in sub:\n",
    "        pid = str(post.id)\n",
    "        if pid not in votes: #if new post, add it to the dictionary\n",
    "            votes[pid] = [post.ups - post.downs] #get the upvotes of the post\n",
    "            totalcomments[pid] = [post.num_comments] #get number of comments\n",
    "            timestamps[pid] = [post.created_utc] #store the timestamps of each post. still need to convert later.\n",
    "        else:#just in case we get some repeating posts\n",
    "            pass\n",
    "    \n",
    "    upvotes = pd.DataFrame(list(votes.values()),index=votes.keys())\n",
    "    upvotes.to_csv('./votes.csv',index_label='id',mode='w+')\n",
    "\n",
    "    comments = pd.DataFrame(list(totalcomments.values()),index=totalcomments.keys())\n",
    "    comments.to_csv('./comments.csv',index_label='id',mode='w+')\n",
    "\n",
    "    times = pd.DataFrame(list(timestamps.values()),index=timestamps.keys())\n",
    "    times.to_csv('./post_time.csv',index_label='id',mode='w+')\n",
    "\n",
    "    on = pd.DataFrame(list(online.values()),index=online.keys())\n",
    "    on.to_csv('./online_users.csv',index_label='timestamp',mode='w+')\n",
    "    \n",
    "    return votes, totalcomments, timestamps, online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell once for initialization or when you want to restart data collection\n",
    "\n",
    "reddit = praw.Reddit(client_id='eOqj6Q2BiQQyKQ', client_secret='1hqeAwOvlkY1PYw51ewhbrItd5k', user_agent='Reddit WebScrapping')\n",
    "\n",
    "sub_title = 'funny' #title of subreddit to scrape\n",
    "votes = {} #store post ids and votes. Positive votes and NEGATIVE votes (when post.downs is > 0)\n",
    "totalcomments = {} #store post ids and the corresponding number of comments\n",
    "timestamps = {} #store timestamp of post creation just so we can tell what day/hour\n",
    "online = {'timestamp':[],'users_online':[]} #store number of online users and timestamp of subreddit\n",
    "num_data = 48 #how many datapoints we want per post, right now it is assuming 24hr with 30min intervals.\n",
    "subred = reddit.subreddit(sub_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell manually every 1hr or 30mins whenever\n",
    "#using this method, we cant put a cap on when to stop collecting new data so we just have to manually drop data.\n",
    "votes, totalcomments, timestamps, online = get_data(sub_title, subred, reddit, votes, totalcomments, timestamps, online, num_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some test stuff for reading in the csv and dropping NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsrx38</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsrvp8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsrvn3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsrvff</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsrv4m</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dsruvh</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dsruqj</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dsru7k</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dsrtsg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dsrt0s</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dsrxzf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dsry4n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   0   1   2   3     4\n",
       "0   dsrx38   2   4   5   5   5.0\n",
       "1   dsrvp8   4   4   4   4   4.0\n",
       "2   dsrvn3   5   5   5   5   5.0\n",
       "3   dsrvff  13  14  14  14  15.0\n",
       "4   dsrv4m   4   4   4   4   4.0\n",
       "5   dsruvh   6   7   7   7   7.0\n",
       "6   dsruqj   6   6   6   6   8.0\n",
       "7   dsru7k   1   1   1   0   0.0\n",
       "8   dsrtsg   3   3   3   3   3.0\n",
       "9   dsrt0s   9   9   9   9   9.0\n",
       "10  dsrxzf   1   1   1   1   1.0\n",
       "11  dsry4n   1   1   1   1   NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('test2_votes.csv')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsrx38</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsrvp8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsrvn3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsrvff</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsrv4m</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dsruvh</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dsruqj</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dsru7k</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dsrtsg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dsrt0s</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dsrxzf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   0   1   2   3     4\n",
       "0   dsrx38   2   4   5   5   5.0\n",
       "1   dsrvp8   4   4   4   4   4.0\n",
       "2   dsrvn3   5   5   5   5   5.0\n",
       "3   dsrvff  13  14  14  14  15.0\n",
       "4   dsrv4m   4   4   4   4   4.0\n",
       "5   dsruvh   6   7   7   7   7.0\n",
       "6   dsruqj   6   6   6   6   8.0\n",
       "7   dsru7k   1   1   1   0   0.0\n",
       "8   dsrtsg   3   3   3   3   3.0\n",
       "9   dsrt0s   9   9   9   9   9.0\n",
       "10  dsrxzf   1   1   1   1   1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timestamp</td>\n",
       "      <td>1.573099e+09</td>\n",
       "      <td>1.573099e+09</td>\n",
       "      <td>1.573099e+09</td>\n",
       "      <td>1.573099e+09</td>\n",
       "      <td>1.573099e+09</td>\n",
       "      <td>1.573099e+09</td>\n",
       "      <td>1.573099e+09</td>\n",
       "      <td>1.573099e+09</td>\n",
       "      <td>1.573099e+09</td>\n",
       "      <td>1.573099e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>users_online</td>\n",
       "      <td>4.101500e+04</td>\n",
       "      <td>4.101500e+04</td>\n",
       "      <td>4.101500e+04</td>\n",
       "      <td>4.101500e+04</td>\n",
       "      <td>4.101500e+04</td>\n",
       "      <td>4.101500e+04</td>\n",
       "      <td>4.101500e+04</td>\n",
       "      <td>4.101500e+04</td>\n",
       "      <td>4.101500e+04</td>\n",
       "      <td>4.101500e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp             0             1             2             3  \\\n",
       "0     timestamp  1.573099e+09  1.573099e+09  1.573099e+09  1.573099e+09   \n",
       "1  users_online  4.101500e+04  4.101500e+04  4.101500e+04  4.101500e+04   \n",
       "\n",
       "              4             5             6             7             8  \\\n",
       "0  1.573099e+09  1.573099e+09  1.573099e+09  1.573099e+09  1.573099e+09   \n",
       "1  4.101500e+04  4.101500e+04  4.101500e+04  4.101500e+04  4.101500e+04   \n",
       "\n",
       "              9  \n",
       "0  1.573099e+09  \n",
       "1  4.101500e+04  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pd.read_csv('test2_online_users.csv')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
